{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fernanda/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import glob\n",
    "from hmmlearn.hmm import GaussianHMM, MultinomialHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_cer = glob.glob('features_projeto_IA369Y/treinamento/certeza/*.csv')\n",
    "datas_inc = glob.glob('features_projeto_IA369Y/treinamento/incerteza/*.csv')\n",
    "#datas_control = glob.glob('features_projeto_IA369Y/controles/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(datas):\n",
    "    feat_list = []\n",
    "    for file in datas:\n",
    "        df = pd.read_csv(file, sep=';')\n",
    "        #df1 = df[df.columns[2:4]]\n",
    "        df1 = df.loc[:, 'alphaRatio_sma3': 'F3amplitudeLogRelF0_sma3nz'].values\n",
    "        d = np.array(df1)\n",
    "        #print (d.shape)\n",
    "        feat_list.append(d)\n",
    "        lenghts = []\n",
    "        for i in range(len(feat_list)):\n",
    "            lenghts.append(len(feat_list[i]))\n",
    "        #print (df1)\n",
    "    f = np.vstack(feat_list)\n",
    "    return f, lenghts, feat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "f_cer, len_cer, list_fcer = select_features(datas_cer)\n",
    "f_inc, len_inc, list_finc = select_features(datas_inc)\n",
    "#f_control, len_control = select_features(datas_control)\n",
    "\n",
    "#features = np.hstack(f_cer, f_inc)\n",
    "\n",
    "print (len(len_cer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvergenceMonitor(history=[-322985.65026263945, -322985.6500779627], iter=10,\n",
      "          n_iter=50, tol=0.01, verbose=False)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model1 = GaussianHMM(n_components=2, covariance_type='diag', n_iter=50)\n",
    "#Parâmetros que determina a topologia left-right\n",
    "#model1.startprob_ = np.array([1.0, 0.0, 0.0])#, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]) # len(stratprob) = n_components\n",
    "#model1.transmat_ = np.array([[0.5, 0.5, 0.0],\n",
    "                           # [0.0, 0.5, 0.5],\n",
    "                           # [0.0, 0.0, 1.0]])\n",
    "#model1.fit(f_control, len_cer)\n",
    "model1.fit(f_cer, len_cer)\n",
    "\n",
    "print (model1.monitor_)\n",
    "print (model1.monitor_.converged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvergenceMonitor(history=[-338461.7431665952, -338461.743118681], iter=9,\n",
      "          n_iter=50, tol=0.01, verbose=False)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "model2 = GaussianHMM(n_components=2, covariance_type='diag', n_iter=50)\n",
    "model2.fit(f_inc, len_inc)\n",
    "print (model2.monitor_)\n",
    "print (model2.monitor_.converged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapa de validação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_v_cer = glob.glob('features_projeto_IA369Y/validacao/certeza/*.csv')\n",
    "datas_v_inc = glob.glob('features_projeto_IA369Y/validacao/incerteza/*.csv')\n",
    "\n",
    "v_cer, ven_cer, list_vcer = select_features(datas_v_cer)\n",
    "v_inc, ven_inc, list_vinc = select_features(datas_v_inc)\n",
    "\n",
    "#print (list_vcer[0].shape)\n",
    "#print (len(list_vcer))\n",
    "#print (ven_cer)\n",
    "#print (v_cer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validação para certeza\n",
      "taxa de acerto: 72.72727272727273 taxa de erro: 27.27272727272727\n",
      "Validação para incerteza\n",
      "taxa de acerto: 54.54545454545454 taxa de erro: 45.45454545454545\n"
     ]
    }
   ],
   "source": [
    "# Verificar a quantidade de acerto\n",
    "# Para os áudios classificados como CERTEZA\n",
    "def taxa_cer(list_vcer): #taxa de erro e acerto em porcentagem\n",
    "    erros1 = []\n",
    "    acertos1 = []\n",
    "    for val in range(len(list_vcer)):\n",
    "        prob1 = model1.score(list_vcer[val])\n",
    "        prob2 = model2.score(list_vcer[val])\n",
    "        if prob1 > prob2:\n",
    "            acertos1.append(['certeza'])\n",
    "        else:\n",
    "            erros1.append(['incerteza'])\n",
    "    taxa_ac1 = (len(acertos1))/len(list_vcer)*100\n",
    "    taxa_er1 = (len(erros1))/len(list_vcer)*100\n",
    "    print ('taxa de acerto:', taxa_ac1, 'taxa de erro:', taxa_er1)\n",
    "    return taxa_ac1, taxa_er1\n",
    "\n",
    "# Para os áudios classificados como INCERTEZA\n",
    "def taxa_inc(list_vinc): #taxa de erro e acerto em porcentagem\n",
    "    erros2 = []\n",
    "    acertos2 = []\n",
    "    for val2 in range(len(list_vinc)):\n",
    "        prob3 = model1.score(list_vinc[val2])\n",
    "        prob4 = model2.score(list_vinc[val2])\n",
    "        if prob3 > prob4:\n",
    "            erros2.append(['certeza'])\n",
    "        else:\n",
    "            acertos2.append(['incerteza'])\n",
    "    taxa_ac2 = (len(acertos2))/len(list_vinc)*100\n",
    "    taxa_er2 = (len(erros2))/len(list_vinc)*100\n",
    "    print ('taxa de acerto:', taxa_ac2, 'taxa de erro:', taxa_er2)\n",
    "    return taxa_ac2, taxa_er2\n",
    "\n",
    "\n",
    "print ('Validação para certeza')\n",
    "ac1, er1 = taxa_cer(list_vcer)\n",
    "\n",
    "print ('Validação para incerteza')\n",
    "ac2, er2 = taxa_inc(list_vinc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_feature_test(path=''):\n",
    "    df = pd.read_csv(path, sep=';')\n",
    "    df1 = df.loc[:, 'alphaRatio_sma3': 'F3amplitudeLogRelF0_sma3nz'].values\n",
    "    d = np.array(df1)\n",
    "    #print (d.shape)\n",
    "    lenghts = []\n",
    "    for i in range(len(d)):\n",
    "        lenghts.append(len(d[i]))\n",
    "    #print (df1)\n",
    "    f = np.vstack(d)\n",
    "    return f, lenghts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_t = 'features_projeto_IA369Y/certeza/I22questao13.csv'\n",
    "path_t2 = 'features_projeto_IA369Y/incerteza/I21questao11.csv'\n",
    "\n",
    "f_test_cer, len_test_cer = select_feature_test(path_t)\n",
    "f2_test_cer, len2_test_cer = select_feature_test(path_t2)\n",
    "\n",
    "# Teste das perguntas de controle\n",
    "#certeza\n",
    "prob1 = model1.score(f_test_cer)\n",
    "prob2 = model2.score(f_test_cer)\n",
    "#print ('treino certeza e teste certeza:', prob1)\n",
    "#print ('treino incerteza e teste certeza:', prob2)\n",
    "\n",
    "#incerteza\n",
    "prob3 = model1.score(f2_test_cer)\n",
    "prob4 = model2.score(f2_test_cer)\n",
    "#print ('treino incerteza e teste incerteza:', prob3)\n",
    "#print ('treino incerteza e teste incerteza:', prob4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incerteza\n"
     ]
    }
   ],
   "source": [
    "#Incerteza\n",
    "if prob3 > prob4:\n",
    "    print ('certeza')\n",
    "else:\n",
    "    print ('incerteza')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "certeza\n"
     ]
    }
   ],
   "source": [
    "#Certeza\n",
    "if prob1 > prob2:\n",
    "    print ('certeza')\n",
    "else:\n",
    "    print ('incerteza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incerteza\n"
     ]
    }
   ],
   "source": [
    "# Utilizando o audio I22_questão1:\n",
    "path1 = ('I22questao2.csv')\n",
    "# Utilizando o audio I22_questão2:\n",
    "#path2 = ('I22questao2.csv')\n",
    "\n",
    "out_cer, l_cer = select_feature_test(path1)\n",
    "\n",
    "prob_out_cer = model1.score(out_cer)\n",
    "prob_out_inc = model2.score(out_cer)\n",
    "\n",
    "#print (prob_out_cer)\n",
    "#print (prob_out_inc)\n",
    "\n",
    "if prob_out_cer > prob_out_inc:\n",
    "    print ('certeza')\n",
    "else:\n",
    "    print ('incerteza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
